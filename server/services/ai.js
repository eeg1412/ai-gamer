import { GoogleGenAI } from '@google/genai'

/**
 * AIè§£è¯´æœåŠ¡
 * ä½¿ç”¨Google Geminiè¿›è¡Œæ¸¸æˆç”»é¢åˆ†æå’Œè§£è¯´ç”Ÿæˆ
 */
export class AIService {
  constructor(config, dbService = null) {
    this.config = config
    this.db = dbService
    this.ai = null
    this.initialized = false
    this.init()
  }

  /**
   * è®¾ç½®æ•°æ®åº“æœåŠ¡ï¼ˆç”¨äºTokenç»Ÿè®¡ï¼‰
   */
  setDatabase(dbService) {
    this.db = dbService
  }

  /**
   * åˆå§‹åŒ–AIå®¢æˆ·ç«¯
   */
  init() {
    if (!this.config.apiKey) {
      console.warn('âš ï¸ æœªé…ç½®GEMINI_API_KEYï¼ŒAIåŠŸèƒ½å°†ä¸å¯ç”¨')
      return
    }

    try {
      this.ai = new GoogleGenAI({ apiKey: this.config.apiKey })
      this.initialized = true
      console.log('âœ… Gemini AIæœåŠ¡å·²åˆå§‹åŒ–')
    } catch (error) {
      console.error('âŒ Gemini AIåˆå§‹åŒ–å¤±è´¥:', error.message)
    }
  }

  /**
   * æ›´æ–°é…ç½®
   */
  updateConfig(newConfig) {
    const needReinit =
      newConfig.apiKey !== this.config.apiKey ||
      newConfig.model !== this.config.model

    this.config = { ...this.config, ...newConfig }

    if (needReinit) {
      console.log('ğŸ”„ AIé…ç½®å·²æ›´æ”¹ï¼Œæ­£åœ¨é‡æ–°åˆå§‹åŒ–...')
      this.init()
    }
  }

  /**
   * è·å–æœåŠ¡çŠ¶æ€
   */
  getStatus() {
    return {
      initialized: this.initialized,
      model: this.config.model
    }
  }

  /**
   * åˆ†ææ¸¸æˆç”»é¢å¹¶ç”Ÿæˆè§£è¯´
   * @param {string} imageBase64 - Base64ç¼–ç çš„å›¾ç‰‡
   * @param {string} systemPrompt - ç³»ç»Ÿæç¤ºè¯ï¼ˆè§’è‰²è®¾å®šï¼‰
   * @param {string} userPrompt - ç”¨æˆ·æç¤ºè¯ï¼ˆè§£è¯´è¦æ±‚ï¼‰
   * @param {Object} options - é¢å¤–é€‰é¡¹
   * @returns {Promise<string>} è§£è¯´æ–‡æœ¬
   */
  async generateCommentary(
    imageBase64,
    systemPrompt,
    userPrompt,
    options = {}
  ) {
    if (!this.initialized) {
      throw new Error('AIæœåŠ¡æœªåˆå§‹åŒ–')
    }

    try {
      const contents = [
        {
          role: 'user',
          parts: [
            {
              inlineData: {
                mimeType: 'image/jpeg',
                data: imageBase64
              }
            },
            {
              text: userPrompt || 'è¯·æ ¹æ®è¿™ä¸ªæ¸¸æˆç”»é¢è¿›è¡Œè§£è¯´'
            }
          ]
        }
      ]

      const response = await this.ai.models.generateContent({
        model: this.config.model,
        contents: contents,
        config: {
          systemInstruction:
            systemPrompt ||
            'ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ¸¸æˆè§£è¯´å‘˜ï¼Œé£æ ¼å¹½é»˜é£è¶£ï¼Œå–„äºåˆ†ææ¸¸æˆå±€åŠ¿ã€‚',
          maxOutputTokens: options.maxTokens || 200,
          temperature: options.temperature || 0.8
        }
      })

      // è®°å½•Tokenä½¿ç”¨
      const text = response.text || 'ï¼ˆæ— æ³•ç”Ÿæˆè§£è¯´ï¼‰'
      this.recordTokenUsage('commentary', response, text)

      return text
    } catch (error) {
      console.error('AIè§£è¯´ç”Ÿæˆå¤±è´¥:', error.message)
      throw error
    }
  }

  /**
   * ç”Ÿæˆæ–‡å­—è§£è¯´ï¼ˆä¸éœ€è¦å›¾ç‰‡ï¼‰
   * @param {string} text - è¦è§£è¯´çš„æ–‡å­—å†…å®¹
   * @param {string} systemPrompt - ç³»ç»Ÿæç¤ºè¯
   * @param {Object} options - é¢å¤–é€‰é¡¹
   * @returns {Promise<string>} è§£è¯´æ–‡æœ¬
   */
  async generateTextCommentary(text, systemPrompt, options = {}) {
    if (!this.initialized) {
      throw new Error('AIæœåŠ¡æœªåˆå§‹åŒ–')
    }

    try {
      const response = await this.ai.models.generateContent({
        model: this.config.model,
        contents: text,
        config: {
          systemInstruction:
            systemPrompt || 'ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ¸¸æˆè§£è¯´å‘˜ï¼Œé£æ ¼å¹½é»˜é£è¶£ã€‚',
          maxOutputTokens: options.maxTokens || 200,
          temperature: options.temperature || 0.8
        }
      })

      // è®°å½•Tokenä½¿ç”¨
      const resultText = response.text || 'ï¼ˆæ— æ³•ç”Ÿæˆè§£è¯´ï¼‰'
      this.recordTokenUsage('text_commentary', response, resultText)

      return resultText
    } catch (error) {
      console.error('AIæ–‡å­—è§£è¯´ç”Ÿæˆå¤±è´¥:', error.message)
      throw error
    }
  }

  /**
   * æµå¼ç”Ÿæˆè§£è¯´ï¼ˆç”¨äºé•¿è§£è¯´ï¼‰
   * @param {string} imageBase64 - Base64ç¼–ç çš„å›¾ç‰‡
   * @param {string} systemPrompt - ç³»ç»Ÿæç¤ºè¯
   * @param {string} userPrompt - ç”¨æˆ·æç¤ºè¯
   * @param {Function} onChunk - æ¯ä¸ªchunkçš„å›è°ƒ
   */
  async generateCommentaryStream(
    imageBase64,
    systemPrompt,
    userPrompt,
    onChunk
  ) {
    if (!this.initialized) {
      throw new Error('AIæœåŠ¡æœªåˆå§‹åŒ–')
    }

    try {
      const contents = [
        {
          role: 'user',
          parts: [
            {
              inlineData: {
                mimeType: 'image/jpeg',
                data: imageBase64
              }
            },
            {
              text: userPrompt || 'è¯·æ ¹æ®è¿™ä¸ªæ¸¸æˆç”»é¢è¿›è¡Œè§£è¯´'
            }
          ]
        }
      ]

      const response = await this.ai.models.generateContentStream({
        model: this.config.model,
        contents: contents,
        config: {
          systemInstruction: systemPrompt || 'ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ¸¸æˆè§£è¯´å‘˜ã€‚',
          temperature: 0.8
        }
      })

      let fullText = ''
      for await (const chunk of response) {
        const text = chunk.text || ''
        fullText += text
        if (onChunk) {
          onChunk(text, fullText)
        }
      }

      return fullText
    } catch (error) {
      console.error('AIæµå¼è§£è¯´ç”Ÿæˆå¤±è´¥:', error.message)
      throw error
    }
  }

  /**
   * å›å¤TwitchèŠå¤©æ¶ˆæ¯
   * @param {string} chatMessage - èŠå¤©æ¶ˆæ¯å†…å®¹
   * @param {string} username - ç”¨æˆ·å
   * @param {string} systemPrompt - ç³»ç»Ÿæç¤ºè¯
   * @param {string} memoryContext - è®°å¿†ä¸Šä¸‹æ–‡
   * @param {Object} options - é¢å¤–é€‰é¡¹
   * @returns {Promise<string>} å›å¤æ–‡æœ¬
   */
  async replyToChat(
    chatMessage,
    username,
    systemPrompt,
    memoryContext = '',
    options = {}
  ) {
    if (!this.initialized) {
      throw new Error('AIæœåŠ¡æœªåˆå§‹åŒ–')
    }

    try {
      let fullPrompt =
        systemPrompt ||
        'ä½ æ˜¯ä¸€ä½å‹å¥½çš„æ¸¸æˆä¸»æ’­ï¼Œæ­£åœ¨ä¸è§‚ä¼—äº’åŠ¨ã€‚è¯·ç”¨ç®€çŸ­æœ‰è¶£çš„æ–¹å¼å›å¤è§‚ä¼—çš„æ¶ˆæ¯ã€‚'

      if (memoryContext) {
        fullPrompt += `\n\nå½“å‰è®°å¿†ä¸Šä¸‹æ–‡ï¼š\n${memoryContext}`
      }

      const userMessage = `è§‚ä¼— "${username}" è¯´: "${chatMessage}"\n\nè¯·ç”¨ç®€çŸ­æœ‰è¶£çš„æ–¹å¼å›å¤è¿™æ¡æ¶ˆæ¯ï¼ˆæ§åˆ¶åœ¨50å­—ä»¥å†…ï¼‰ï¼š`

      const response = await this.ai.models.generateContent({
        model: this.config.model,
        contents: userMessage,
        config: {
          systemInstruction: fullPrompt,
          maxOutputTokens: options.maxTokens || 100,
          temperature: options.temperature || 0.9
        }
      })

      const text = response.text || 'è°¢è°¢ä½ çš„æ¶ˆæ¯ï¼'
      this.recordTokenUsage('chat_reply', response, text)

      return text
    } catch (error) {
      console.error('AIå›å¤èŠå¤©å¤±è´¥:', error.message)
      throw error
    }
  }

  /**
   * è®°å½•Tokenä½¿ç”¨æƒ…å†µ
   */
  recordTokenUsage(type, response, outputText) {
    if (!this.db) return

    try {
      // å…¼å®¹ä¸åŒç‰ˆæœ¬çš„ SDK å“åº”ç»“æ„
      const usageMetadata =
        response.usageMetadata ||
        (response.response && response.response.usageMetadata) ||
        (response.metadata && response.metadata.usage) ||
        {}

      const inputTokens =
        usageMetadata.promptTokenCount ||
        usageMetadata.prompt_token_count ||
        (type === 'commentary' ? 800 : this.estimateTokens(type)) // Gemini 1.5/2.0 vision typically ~768 tokens per image

      const outputTokens =
        usageMetadata.candidatesTokenCount ||
        usageMetadata.candidates_token_count ||
        usageMetadata.output_token_count ||
        (outputText ? this.estimateTokens(outputText) : 50)

      this.db.recordTokenUsage(
        type,
        inputTokens,
        outputTokens,
        this.config.model
      )
    } catch (error) {
      console.error('è®°å½•Tokenä½¿ç”¨å¤±è´¥:', error.message)
    }
  }

  /**
   * ä¼°ç®—Tokenæ•°é‡
   */
  estimateTokens(text) {
    if (!text) return 0
    const chineseChars = (text.match(/[\u4e00-\u9fff]/g) || []).length
    const otherChars = text.length - chineseChars
    return Math.ceil(chineseChars / 1.5 + otherChars / 4)
  }
}
