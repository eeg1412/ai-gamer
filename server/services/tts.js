import * as sdk from 'microsoft-cognitiveservices-speech-sdk'
import fs from 'fs/promises'
import path from 'path'
import { fileURLToPath } from 'url'
import { v4 as uuidv4 } from 'uuid'

const __filename = fileURLToPath(import.meta.url)
const __dirname = path.dirname(__filename)

/**
 * TTSè¯­éŸ³åˆæˆæœåŠ¡
 * ä½¿ç”¨ Azure Cognitive Services Speech SDK å°†æ–‡å­—è½¬æ¢ä¸ºè¯­éŸ³
 */
export class TTSService {
  constructor(config) {
    this.config = config
    this.audioDir = path.join(__dirname, '../../audio')
    this.voices = []
    this.speechConfig = null
    this.init()
  }

  /**
   * åˆå§‹åŒ–TTSæœåŠ¡
   */
  async init() {
    try {
      // ç¡®ä¿éŸ³é¢‘ç›®å½•å­˜åœ¨
      await fs.mkdir(this.audioDir, { recursive: true })

      // æ£€æŸ¥Azureé…ç½®
      if (!this.config.azureKey || !this.config.azureRegion) {
        console.warn(
          'âš ï¸ æœªé…ç½®AZURE_SPEECH_KEYæˆ–AZURE_SPEECH_REGIONï¼ŒTTSåŠŸèƒ½å°†ä¸å¯ç”¨'
        )
        return
      }

      // åˆå§‹åŒ– Speech Config
      this.speechConfig = sdk.SpeechConfig.fromSubscription(
        this.config.azureKey,
        this.config.azureRegion
      )

      // è®¾ç½®è¯­éŸ³
      this.speechConfig.speechSynthesisVoiceName =
        this.config.voice || 'zh-CN-XiaoxiaoNeural'

      console.log('âœ… TTSæœåŠ¡å·²åˆå§‹åŒ– (Azure Speech)')
    } catch (error) {
      console.error('âŒ TTSåˆå§‹åŒ–å¤±è´¥:', error.message)
    }
  }

  /**
   * è·å–å¯ç”¨çš„è¯­éŸ³åˆ—è¡¨
   */
  async getAvailableVoices() {
    if (this.voices.length > 0) {
      return this.voices
    }

    // å¦‚æœé…ç½®å¯ç”¨ï¼Œå°è¯•ä»Azureè·å–
    if (this.speechConfig) {
      try {
        const synthesizer = new sdk.SpeechSynthesizer(this.speechConfig, null)
        const result = await synthesizer.getVoicesAsync()

        if (result.voices && result.voices.length > 0) {
          this.voices = result.voices
            .filter(v => v.locale.startsWith('zh-'))
            .map(v => ({
              ShortName: v.shortName,
              FriendlyName: `${v.localName} (${v.locale})`
            }))
          synthesizer.close()
          return this.voices
        }
        synthesizer.close()
      } catch (error) {
        console.error('è·å–è¯­éŸ³åˆ—è¡¨å¤±è´¥:', error.message)
      }
    }

    // è¿”å›é»˜è®¤å¸¸ç”¨ä¸­æ–‡è¯­éŸ³åˆ—è¡¨
    this.voices = [
      {
        ShortName: 'zh-CN-XiaoxiaoNeural',
        FriendlyName: 'æ™“æ™“ (å¥³å£°, æ™®é€šè¯)'
      },
      { ShortName: 'zh-CN-YunxiNeural', FriendlyName: 'äº‘å¸Œ (ç”·å£°, æ™®é€šè¯)' },
      { ShortName: 'zh-CN-YunjianNeural', FriendlyName: 'äº‘å¥ (ç”·å£°, æ™®é€šè¯)' },
      { ShortName: 'zh-CN-XiaoyiNeural', FriendlyName: 'æ™“ä¼Š (å¥³å£°, æ™®é€šè¯)' },
      {
        ShortName: 'zh-CN-YunyangNeural',
        FriendlyName: 'äº‘æ‰¬ (ç”·å£°, æ–°é—»é£æ ¼)'
      },
      {
        ShortName: 'zh-CN-XiaochenNeural',
        FriendlyName: 'æ™“è¾° (å¥³å£°, æ™®é€šè¯)'
      },
      { ShortName: 'zh-CN-XiaohanNeural', FriendlyName: 'æ™“æ¶µ (å¥³å£°, æ™®é€šè¯)' },
      {
        ShortName: 'zh-CN-XiaomengNeural',
        FriendlyName: 'æ™“æ¢¦ (å¥³å£°, æ™®é€šè¯)'
      },
      { ShortName: 'zh-CN-XiaomoNeural', FriendlyName: 'æ™“å¢¨ (å¥³å£°, æ™®é€šè¯)' },
      { ShortName: 'zh-CN-XiaoruiNeural', FriendlyName: 'æ™“ç¿ (å¥³å£°, æ™®é€šè¯)' },
      {
        ShortName: 'zh-CN-XiaoshuangNeural',
        FriendlyName: 'æ™“åŒ (å¥³å£°, å„¿ç«¥)'
      },
      {
        ShortName: 'zh-CN-XiaoxuanNeural',
        FriendlyName: 'æ™“è± (å¥³å£°, æ™®é€šè¯)'
      },
      { ShortName: 'zh-CN-XiaoyanNeural', FriendlyName: 'æ™“é¢œ (å¥³å£°, æ™®é€šè¯)' },
      {
        ShortName: 'zh-CN-XiaozhenNeural',
        FriendlyName: 'æ™“ç”„ (å¥³å£°, æ™®é€šè¯)'
      },
      { ShortName: 'zh-TW-HsiaoChenNeural', FriendlyName: 'æ›‰è‡» (å¥³å£°, å°æ¹¾)' },
      { ShortName: 'zh-TW-YunJheNeural', FriendlyName: 'é›²å“² (ç”·å£°, å°æ¹¾)' },
      { ShortName: 'zh-HK-HiuGaaiNeural', FriendlyName: 'æ›‰ä½³ (å¥³å£°, é¦™æ¸¯)' },
      { ShortName: 'zh-HK-WanLungNeural', FriendlyName: 'é›²é¾ (ç”·å£°, é¦™æ¸¯)' }
    ]

    return this.voices
  }

  /**
   * è·å–ä¸­æ–‡è¯­éŸ³åˆ—è¡¨
   */
  async getChineseVoices() {
    return await this.getAvailableVoices()
  }

  /**
   * å°†æ–‡å­—è½¬æ¢ä¸ºè¯­éŸ³
   * @param {string} text - è¦è½¬æ¢çš„æ–‡å­—
   * @param {Object} options - TTSé€‰é¡¹
   * @returns {Promise<{success: boolean, audioUrl: string, filename: string}>}
   */
  async textToSpeech(text, options = {}) {
    if (!text || text.trim().length === 0) {
      return { success: false, message: 'æ–‡å­—å†…å®¹ä¸ºç©º' }
    }

    if (!this.speechConfig) {
      console.warn('TTSä¸å¯ç”¨ï¼Œè¯·é…ç½®Azure SpeechæœåŠ¡')
      return { success: false, message: 'Azure Speechæœªé…ç½®' }
    }

    const voice = options.voice || this.config.voice
    const rate = options.rate || this.config.rate || '+0%'

    const filename = `${uuidv4()}.mp3`
    const filePath = path.join(this.audioDir, filename)

    try {
      // åˆ›å»ºä¸´æ—¶é…ç½®
      const tempConfig = sdk.SpeechConfig.fromSubscription(
        this.config.azureKey,
        this.config.azureRegion
      )
      tempConfig.speechSynthesisVoiceName = voice
      tempConfig.speechSynthesisOutputFormat =
        sdk.SpeechSynthesisOutputFormat.Audio24Khz96KBitRateMonoMp3

      // åˆ›å»ºéŸ³é¢‘é…ç½®
      const audioConfig = sdk.AudioConfig.fromAudioFileOutput(filePath)

      // åˆ›å»ºåˆæˆå™¨
      const synthesizer = new sdk.SpeechSynthesizer(tempConfig, audioConfig)

      // æ„å»ºSSMLä»¥æ”¯æŒè¯­é€Ÿè°ƒæ•´
      const ssml = `<speak version="1.0" xmlns="http://www.w3.org/2001/10/synthesis" xml:lang="zh-CN">
        <voice name="${voice}">
          <prosody rate="${rate}">
            ${text}
          </prosody>
        </voice>
      </speak>`

      // æ‰§è¡Œåˆæˆ
      const result = await new Promise((resolve, reject) => {
        synthesizer.speakSsmlAsync(
          ssml,
          result => {
            synthesizer.close()
            resolve(result)
          },
          error => {
            synthesizer.close()
            reject(error)
          }
        )
      })

      if (result.reason === sdk.ResultReason.SynthesizingAudioCompleted) {
        console.log(`ğŸ”Š TTSç”ŸæˆæˆåŠŸ: ${filename}`)
        return {
          success: true,
          filename,
          audioUrl: `/audio/${filename}`,
          text
        }
      } else {
        throw new Error(`è¯­éŸ³åˆæˆå¤±è´¥: ${result.errorDetails}`)
      }
    } catch (error) {
      console.error('TTSç”Ÿæˆå¤±è´¥:', error.message)
      return {
        success: false,
        message: error.message
      }
    }
  }

  /**
   * è·å–éŸ³é¢‘Bufferï¼ˆä¸ä¿å­˜æ–‡ä»¶ï¼‰
   * @param {string} text - è¦è½¬æ¢çš„æ–‡å­—
   * @param {Object} options - TTSé€‰é¡¹
   * @returns {Promise<Buffer>}
   */
  async getAudioBuffer(text, options = {}) {
    const result = await this.textToSpeech(text, options)
    if (result.success) {
      const filePath = path.join(this.audioDir, result.filename)
      const buffer = await fs.readFile(filePath)
      // å¯é€‰ï¼šè¯»å–ååˆ é™¤æ–‡ä»¶
      // await fs.unlink(filePath);
      return buffer
    }
    throw new Error(result.message)
  }

  /**
   * æ¸…ç†æ—§çš„éŸ³é¢‘æ–‡ä»¶
   * @param {number} maxAge - æœ€å¤§ä¿ç•™æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
   */
  async cleanupOldFiles(maxAge = 3600000) {
    // é»˜è®¤1å°æ—¶
    try {
      const files = await fs.readdir(this.audioDir)
      const now = Date.now()

      for (const file of files) {
        if (!file.endsWith('.mp3')) continue

        const filePath = path.join(this.audioDir, file)
        const stats = await fs.stat(filePath)

        if (now - stats.mtimeMs > maxAge) {
          await fs.unlink(filePath)
          console.log(`ğŸ—‘ï¸ å·²æ¸…ç†æ—§éŸ³é¢‘: ${file}`)
        }
      }
    } catch (error) {
      console.error('æ¸…ç†éŸ³é¢‘æ–‡ä»¶å¤±è´¥:', error.message)
    }
  }

  /**
   * æ›´æ–°TTSé…ç½®
   */
  updateConfig(newConfig) {
    this.config = { ...this.config, ...newConfig }
  }

  /**
   * è·å–å½“å‰é…ç½®
   */
  getConfig() {
    return { ...this.config }
  }
}
